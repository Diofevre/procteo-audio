"""
Application Streamlit VAD pour Procteo-Audio.
Interface pour l'analyse Voice Activity Detection avec Pyannote.
Interface compl√®te avec diagnostic de sant√© et gestion d'erreurs robuste.
"""

import streamlit as st
import os
import platform
from pathlib import Path
import tempfile
import json
from loguru import logger

# Import des modules VAD
from src.audio.pipeline.vad_processor import VADProcessor
from src.audio.utils.token_manager import TokenManager

st.set_page_config(
    page_title="Procteo-Audio - VAD",
    page_icon="üéµ",
    layout="wide"
)

st.title("üéµ Procteo-Audio - Voice Activity Detection")
st.markdown("---")

# Initialisation de la session
if 'vad_processor' not in st.session_state:
    st.session_state.vad_processor = None
if 'vad_results' not in st.session_state:
    st.session_state.vad_results = None
if 'health_status' not in st.session_state:
    st.session_state.health_status = None

# Sidebar pour la configuration
with st.sidebar:
    st.header("‚öôÔ∏è Configuration VAD")
    
    # V√©rification compl√®te de la sant√©
    if st.button("üîç V√©rifier la sant√© du syst√®me", type="primary"):
        st.session_state.health_status = TokenManager.get_health_summary()
        st.rerun()
    
    if st.session_state.health_status:
        health = st.session_state.health_status
        
        # Statut du token
        if health["token_detected"]:
            if health["token_valid"]:
                st.success(f"‚úÖ Token HF d√©tect√© ({health['token_source']})")
            else:
                st.warning("‚ö†Ô∏è Token HF d√©tect√© mais invalide")
        else:
            st.error("‚ùå Token HF manquant")
            st.info("Configurez HF_TOKEN dans .streamlit/secrets.toml")
        
        # Statut du mod√®le
        if health["model_accessible"]:
            st.success(f"‚úÖ Mod√®le accessible: {health['model_target']}")
        else:
            st.error(f"‚ùå Mod√®le inaccessible: {health['model_message']}")
            if health["model_help"]:
                st.info(f"ÔøΩÔøΩ {health['model_help']}")
        
        # Device
        st.info(f"üñ•Ô∏è Device: {health['device']}")
        
        # D√©pendances
        if health.get("pyannote_available", False):
            st.success("‚úÖ Pyannote disponible")
        else:
            st.error("‚ùå Pyannote non disponible")
            st.info(health.get("pyannote_error", ""))
        
        if health.get("soundfile_available", False):
            st.success("‚úÖ SoundFile disponible")
        else:
            st.error("‚ùå SoundFile non disponible")
            st.info(health.get("soundfile_error", ""))
    
    # Param√®tres VAD
    st.subheader("üîß Param√®tres")
    
    # Chargement de la config
    config_path = "config/vad_config.yaml"
    if os.path.exists(config_path):
        try:
            import yaml
            with open(config_path, 'r') as f:
                config = yaml.safe_load(f)
        except:
            config = {
                "confidence_threshold": 0.5,
                "min_duration_s": 0.5,
                "merge_gap_s": 0.3,
                "margin_s": 0.2
            }
    else:
        config = {
            "confidence_threshold": 0.5,
            "min_duration_s": 0.5,
            "merge_gap_s": 0.3,
            "margin_s": 0.2
        }
    
    confidence_threshold = st.slider(
        "Seuil de confiance",
        min_value=0.1,
        max_value=0.9,
        value=config.get("confidence_threshold", 0.5),
        step=0.05
    )
    
    min_duration = st.slider(
        "Dur√©e minimale (s)",
        min_value=0.1,
        max_value=2.0,
        value=config.get("min_duration_s", 0.5),
        step=0.1
    )
    
    merge_gap = st.slider(
        "Gap de fusion (s)",
        min_value=0.1,
        max_value=1.0,
        value=config.get("merge_gap_s", 0.3),
        step=0.1
    )
    
    margin = st.slider(
        "Marge (s)",
        min_value=0.05,
        max_value=0.5,
        value=config.get("margin_s", 0.2),
        step=0.05
    )

# Interface principale
col1, col2 = st.columns([2, 1])

with col1:
    st.header("üìÅ Upload de fichier")
    
    # Upload de fichier
    uploaded_file = st.file_uploader(
        "Choisissez un fichier audio ou vid√©o",
        type=['wav', 'mp3', 'mp4', 'mkv', 'avi', 'mov'],
        help="Formats support√©s: WAV, MP3, MP4, MKV, AVI, MOV"
    )
    
    if uploaded_file is not None:
        # Sauvegarde temporaire
        temp_dir = Path(".tmp")
        temp_dir.mkdir(exist_ok=True)
        
        file_path = temp_dir / uploaded_file.name
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        st.success(f"Fichier sauvegard√©: {file_path}")
        
        # Bouton d'analyse VAD
        if st.button("üöÄ Lancer l'analyse VAD", type="primary"):
            with st.spinner("Initialisation de la pipeline VAD..."):
                try:
                    # Initialisation du processeur
                    if not st.session_state.vad_processor:
                        st.session_state.vad_processor = VADProcessor()
                    
                    # V√©rification de la sant√©
                    health = st.session_state.vad_processor.check_prerequisites()
                    
                    if not health["token_detected"]:
                        st.error("‚ùå Token HF manquant")
                        st.stop()
                    
                    if not health["model_accessible"]:
                        st.error(f"‚ùå Mod√®le inaccessible: {health.get('model_message', 'Erreur inconnue')}")
                        if health.get("model_help"):
                            st.info(f"üí° {health['model_help']}")
                        st.stop()
                    
                    # Initialisation de la pipeline
                    if not st.session_state.vad_processor.initialize_pipeline():
                        st.error(f"‚ùå √âchec de l'initialisation de la pipeline")
                        st.error(f"Erreur: {st.session_state.vad_processor.initialization_error}")
                        st.stop()
                    
                    st.success("‚úÖ Pipeline VAD initialis√©e avec succ√®s")
                    
                except Exception as e:
                    st.error(f"‚ùå Erreur lors de l'initialisation: {e}")
                    st.stop()
            
            with st.spinner("Analyse VAD en cours..."):
                try:
                    # Traitement VAD
                    results = st.session_state.vad_processor.process_audio(str(file_path))
                    
                    if results["success"]:
                        st.session_state.vad_results = results
                        st.success("‚úÖ Analyse VAD termin√©e avec succ√®s")
                        
                        # Sauvegarde des r√©sultats
                        try:
                            output_path = st.session_state.vad_processor.save_results(results)
                            st.info(f"üìÅ R√©sultats sauvegard√©s: {output_path}")
                        except Exception as e:
                            st.warning(f"‚ö†Ô∏è Erreur sauvegarde: {e}")
                    else:
                        st.error(f"‚ùå √âchec de l'analyse VAD: {results.get('error', 'Erreur inconnue')}")
                        
                        # Affichage des d√©tails de sant√©
                        if "health" in results:
                            st.subheader("üîç D√©tails de l'erreur")
                            health = results["health"]
                            
                            if not health["token_detected"]:
                                st.error("Token HF manquant")
                            elif not health["model_accessible"]:
                                st.error(f"Mod√®le inaccessible: {health.get('model_message', '')}")
                                if health.get("model_help"):
                                    st.info(health["model_help"])
                        
                except Exception as e:
                    st.error(f"‚ùå Erreur lors de l'analyse: {e}")
                    logger.error(f"Erreur VAD: {e}")

with col2:
    st.header("üìä M√©triques")
    
    if st.session_state.vad_results:
        results = st.session_state.vad_results
        
        # M√©triques principales
        st.metric("Dur√©e audio", f"{results['metadata']['duration_s']}s")
        st.metric("Segments d√©tect√©s", results['stats']['total_segments'])
        st.metric("Temps de parole", f"{results['stats']['total_speech_time']:.1f}s")
        st.metric("Ratio parole", f"{results['stats']['speech_ratio']:.1%}")
        st.metric("Temps traitement", f"{results['metadata']['processing_time_s']:.1f}s")
        st.metric("RTF", f"{results['metadata']['rtf']:.3f}")
        
        # Bouton de t√©l√©chargement
        if st.button("üíæ T√©l√©charger r√©sultats JSON"):
            json_str = json.dumps(results, indent=2, ensure_ascii=False)
            st.download_button(
                label="üì• T√©l√©charger",
                data=json_str,
                file_name=f"vad_results_{results['metadata']['file_hash']}.json",
                mime="application/json"
            )

# Affichage des r√©sultats
if st.session_state.vad_results:
    results = st.session_state.vad_results
    
    st.header("üìã R√©sultats de l'analyse VAD")
    
    # Tableau des segments
    if results['events']:
        st.subheader("üéØ Segments de parole d√©tect√©s")
        
        # Cr√©ation du DataFrame pour l'affichage
        import pandas as pd
        
        df = pd.DataFrame(results['events'])
        df['start'] = df['start'].round(3)
        df['end'] = df['end'].round(3)
        df['confidence'] = df['confidence'].round(3)
        df['duration'] = df['duration'].round(3)
        
        st.dataframe(df, use_container_width=True)
        
        # Visualisation avec Plotly
        try:
            import plotly.express as px
            
            # Pr√©paration des donn√©es pour le graphique
            plot_data = []
            for i, event in enumerate(results['events']):
                plot_data.append({
                    'Segment': f"Segment {i+1}",
                    'D√©but': event['start'],
                    'Fin': event['end'],
                    'Confiance': event['confidence']
                })
            
            if plot_data:
                fig = px.timeline(
                    plot_data,
                    x_start='D√©but',
                    x_end='Fin',
                    y='Segment',
                    color='Confiance',
                    title="Timeline des segments de parole",
                    color_continuous_scale='viridis'
                )
                
                fig.update_layout(
                    xaxis_title="Temps (secondes)",
                    yaxis_title="Segments",
                    height=400
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
        except ImportError:
            st.warning("‚ö†Ô∏è Plotly non disponible pour la visualisation")
    
    else:
        st.info("üîá Aucun segment de parole d√©tect√©")
    
    # M√©tadonn√©es d√©taill√©es
    with st.expander("üìä M√©tadonn√©es d√©taill√©es"):
        st.json(results['metadata'])
    
    # Statistiques d√©taill√©es
    with st.expander("üìà Statistiques d√©taill√©es"):
        st.json(results['stats'])

# Footer avec informations
st.markdown("---")
st.info("üéØ **Procteo-Audio VAD** - Analyse Voice Activity Detection avec Pyannote")
st.success("‚úÖ **√âtape 2 compl√©t√©e:** VAD Pyannote int√©gr√© avec diagnostic complet")

# V√©rification des d√©pendances (cach√©e dans un expander)
with st.expander("üîç V√©rification des d√©pendances"):
    st.subheader("üì¶ Versions des packages")
    
    try:
        import streamlit as st_lib
        st.write(f"**Streamlit:** {st_lib.__version__}")
    except:
        st.write("**Streamlit:** Version non disponible")
    
    try:
        import torch
        st.write(f"**PyTorch:** {torch.__version__}")
    except:
        st.write("**PyTorch:** Non install√©")
    
    try:
        import torchaudio
        st.write(f"**TorchAudio:** {torchaudio.__version__}")
    except:
        st.write("**TorchAudio:** Non install√©")
    
    try:
        import pyannote
        st.write(f"**Pyannote.audio:** {pyannote.__version__}")
    except:
        st.write("**Pyannote.audio:** Non install√©")
    
    try:
        import soundfile
        st.write(f"**SoundFile:** {soundfile.__version__}")
    except:
        st.write("**SoundFile:** Non install√©")
    
    try:
        import librosa
        st.write(f"**Librosa:** {librosa.__version__}")
    except:
        st.write("**Librosa:** Non install√©")
    
    st.write(f"**Python:** {platform.python_version()}")
    st.write(f"**Syst√®me:** {platform.system()} {platform.release()}")
